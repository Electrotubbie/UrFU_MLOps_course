{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2358b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импортируем нужные библиотеки\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67ea4b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28538</th>\n",
       "      <td>0.43</td>\n",
       "      <td>Premium</td>\n",
       "      <td>968</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.84</td>\n",
       "      <td>2.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53204</th>\n",
       "      <td>0.90</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>3342</td>\n",
       "      <td>6.07</td>\n",
       "      <td>6.02</td>\n",
       "      <td>3.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23420</th>\n",
       "      <td>0.40</td>\n",
       "      <td>Premium</td>\n",
       "      <td>945</td>\n",
       "      <td>4.71</td>\n",
       "      <td>4.67</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20302</th>\n",
       "      <td>0.51</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>1343</td>\n",
       "      <td>5.09</td>\n",
       "      <td>5.14</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6883</th>\n",
       "      <td>1.01</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>3852</td>\n",
       "      <td>6.43</td>\n",
       "      <td>6.46</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45505</th>\n",
       "      <td>0.51</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>2146</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.10</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50544</th>\n",
       "      <td>1.31</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>12825</td>\n",
       "      <td>6.97</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>0.91</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>3884</td>\n",
       "      <td>6.12</td>\n",
       "      <td>6.17</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10105</th>\n",
       "      <td>0.55</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>1871</td>\n",
       "      <td>5.31</td>\n",
       "      <td>5.29</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38992</th>\n",
       "      <td>0.69</td>\n",
       "      <td>Fair</td>\n",
       "      <td>2235</td>\n",
       "      <td>5.58</td>\n",
       "      <td>5.64</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut  price     x     y     z\n",
       "28538   0.43    Premium    968  4.87  4.84  2.96\n",
       "53204   0.90  Very Good   3342  6.07  6.02  3.83\n",
       "23420   0.40    Premium    945  4.71  4.67  2.93\n",
       "20302   0.51      Ideal   1343  5.09  5.14  3.19\n",
       "6883    1.01  Very Good   3852  6.43  6.46  3.99\n",
       "45505   0.51  Very Good   2146  5.06  5.10  3.19\n",
       "50544   1.31      Ideal  12825  6.97  7.00  4.34\n",
       "7612    0.91  Very Good   3884  6.12  6.17  3.82\n",
       "10105   0.55      Ideal   1871  5.31  5.29  3.27\n",
       "38992   0.69       Fair   2235  5.58  5.64  3.42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Считываем данные\n",
    "df = sns.load_dataset('diamonds').drop(columns=[\"color\", \"clarity\", \"depth\", \"table\"])\n",
    "df = df.sample(df.shape[0], ignore_index=True)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d70ebc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53940 entries, 0 to 53939\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype   \n",
      "---  ------  --------------  -----   \n",
      " 0   carat   53940 non-null  float64 \n",
      " 1   cut     53940 non-null  category\n",
      " 2   price   53940 non-null  int64   \n",
      " 3   x       53940 non-null  float64 \n",
      " 4   y       53940 non-null  float64 \n",
      " 5   z       53940 non-null  float64 \n",
      "dtypes: category(1), float64(4), int64(1)\n",
      "memory usage: 2.1 MB\n"
     ]
    }
   ],
   "source": [
    "#Смотрим информацию:тип данных и количество пропусков\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55449a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat    0\n",
       "cut      0\n",
       "price    0\n",
       "x        0\n",
       "y        0\n",
       "z        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Смотрим количество пропусков в датасете\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f53ff634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Наблюдаем количество дубликатов\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ed718eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53483, 6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Удаляем дубликаты\n",
    "df = df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a41658b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Категориальные данные:\t  ['cut'] \n",
      " Число столблцов =  1\n",
      "Числовые данные:\t  ['carat', 'price', 'x', 'y', 'z'] \n",
      " Число столблцов =  5\n"
     ]
    }
   ],
   "source": [
    "#посмотрим на то, какие у нас есть категориальные и численные столбцы\n",
    "\n",
    "cat_columns = [] # создаем пустой список для имен колонок категориальных данных\n",
    "num_columns = [] # создаем пустой список для имен колонок числовых данных\n",
    "\n",
    "for column_name in df.columns: # смотрим на все колонки в датафрейме\n",
    "    if (df[column_name].dtypes == 'category'): # проверяем тип данных для каждой колонки\n",
    "        cat_columns +=[column_name] # если тип объект - то складываем в категориальные данные\n",
    "    else:\n",
    "        num_columns +=[column_name] # иначе - числовые\n",
    "\n",
    "# важно: если признак категориальный, но хранится в формате числовых данных, тогда код не сработает корректно\n",
    "\n",
    "\n",
    "# выводим результат\n",
    "print('Категориальные данные:\\t ',cat_columns, '\\n Число столблцов = ',len(cat_columns))\n",
    "\n",
    "print('Числовые данные:\\t ',  num_columns, '\\n Число столблцов = ',len(num_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff9659a",
   "metadata": {},
   "source": [
    "### Создание датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21ecfdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir df_1 df_2 df_3 df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5247f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание датасетов (Деление на равные датасеты)\n",
    "def df_create(data, n):\n",
    "    \n",
    "    num_dir = 0\n",
    "    before_index = 0\n",
    "    shape = data.shape[0]\n",
    "    \n",
    "    for index in range(int(shape / n), shape, int(shape / n)):\n",
    "        num_dir += 1\n",
    "        create_df = data.iloc[before_index:index]\n",
    "        \n",
    "        #Создаем n-й датасет с шумом\n",
    "        if num_dir == 4:\n",
    "            create_df[\"price\"] = create_df[\"price\"] + \\\n",
    "                100 * np.random.randn(create_df.shape[0])\n",
    "\n",
    "        create_df.to_csv(f\"df_{num_dir}/df.csv\", index=False)\n",
    "            \n",
    "        before_index = index\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de11a7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v.zemov\\AppData\\Local\\Temp\\ipykernel_11252\\30957057.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  create_df[\"price\"] = create_df[\"price\"] + \\\n"
     ]
    }
   ],
   "source": [
    "df_create(df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97415015",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('df_1/df.csv')\n",
    "df_2 = pd.read_csv('df_2/df.csv')\n",
    "df_3 = pd.read_csv('df_3/df.csv')\n",
    "df_4 = pd.read_csv('df_4/df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9d7d5c",
   "metadata": {},
   "source": [
    "### Препроцессинг и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "240fcd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание пайплайна для препроцессинга данных и выполнения прогноза\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\n",
    "                \"encoder\",\n",
    "                OneHotEncoder(drop=\"if_binary\", handle_unknown=\"ignore\", sparse=False),\n",
    "                ['cut'],\n",
    "            ),\n",
    "            (\"scaler\", StandardScaler(), ['carat', 'x', 'y', 'z']),\n",
    "        ]\n",
    "    ),\n",
    "    LinearRegression(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d5d4878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер  (X_train): (10696, 5)\n",
      "Размер (X_test): (2674, 5)\n",
      "Размер  (y_train): (10696,)\n",
      "Размер (y_test): (2674,)\n"
     ]
    }
   ],
   "source": [
    "X = df_1.drop(columns=[\"price\"])\n",
    "y = df_1[\"price\"]\n",
    "\n",
    "# Разделение на обучающий и тестовый наборы данных\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Размер  (X_train):\", X_train.shape)\n",
    "print(\"Размер (X_test):\", X_test.shape)\n",
    "print(\"Размер  (y_train):\", y_train.shape)\n",
    "print(\"Размер (y_test):\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78884a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обучение модели\n",
    "model_predict = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c7fbdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_pedict_price.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохранение обученной модели\n",
    "dump(model_predict, \"model_pedict_price.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3896392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Прогнозирование на тестовом наборе данных\n",
    "y_pred = model_predict.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6235f51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя абсолютная ошибка (MAE): 904.5713818249812\n",
      "Коэффициент детерминации (R^2): 0.8648892632795175\n"
     ]
    }
   ],
   "source": [
    "# Вычисление средней абсолютной ошибки (MAE) и коэффициента детерминации(R^2)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Средняя абсолютная ошибка (MAE):\", MAE)\n",
    "print(\"Коэффициент детерминации (R^2):\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feefe1b1",
   "metadata": {},
   "source": [
    "### Создаем файл для теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "18e14321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytest\n",
    "from joblib import load\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "@pytest.fixture()\n",
    "def load_model():\n",
    "    model = load(\"model_pedict_price.joblib\")\n",
    "    return model\n",
    "\n",
    "\n",
    "@pytest.fixture()\n",
    "def making_prediction(load_model):\n",
    "    data = pd.read_csv(\"df.сsv\")\n",
    "    X = data.drop(columns=\"price\")\n",
    "    y = data[\"price\"]\n",
    "    y_pred = load_model.predict(X)\n",
    "    return y, y_pred\n",
    "\n",
    "\n",
    "def test_MAE(making_prediction):\n",
    "    y, y_pred = making_prediction\n",
    "    assert mean_absolute_error(y, y_pred) < 900\n",
    "\n",
    "\n",
    "def test_R2(making_prediction):\n",
    "    y, y_pred = making_prediction\n",
    "    assert r2_score(y, y_pred) > 0.85\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e8047b",
   "metadata": {},
   "source": [
    "### Тестируем датафреймы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5f71694e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.9.12, pytest-7.1.1, pluggy-1.0.0 -- C:\\Users\\v.zemov\\Anaconda3\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: C:\\Users\\v.zemov\\Desktop\\Master\\2 семестр ИИ\\Автоматизация машин_обучения\\lab_5\n",
      "plugins: anyio-3.7.1\n",
      "collecting ... collected 2 items\n",
      "\n",
      "test.py::test_MAE ERROR                                                  [ 50%]\n",
      "test.py::test_R2 ERROR                                                   [100%]\n",
      "\n",
      "=================================== ERRORS ====================================\n",
      "_________________________ ERROR at setup of test_MAE __________________________\n",
      "\n",
      "load_model = Pipeline(steps=[('columntransformer',\n",
      "                 ColumnTransformer(transformers=[('encoder',\n",
      "                   ...                               ['carat', 'x', 'y', 'z'])])),\n",
      "                ('linearregression', LinearRegression())])\n",
      "\n",
      "    @pytest.fixture()\n",
      "    def making_prediction(load_model):\n",
      ">       data = pd.read_csv(\"df.сsv\")\n",
      "\n",
      "test.py:16: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "..\\..\\..\\..\\..\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "..\\..\\..\\..\\..\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680: in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "..\\..\\..\\..\\..\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575: in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "..\\..\\..\\..\\..\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933: in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "..\\..\\..\\..\\..\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217: in _make_engine\n",
      "    self.handles = get_handle(  # type: ignore[call-overload]\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = 'df.сsv', mode = 'r'\n",
      "\n",
      "    @doc(compression_options=_shared_docs[\"compression_options\"] % \"path_or_buf\")\n",
      "    def get_handle(\n",
      "        path_or_buf: FilePath | BaseBuffer,\n",
      "        mode: str,\n",
      "        *,\n",
      "        encoding: str | None = None,\n",
      "        compression: CompressionOptions = None,\n",
      "        memory_map: bool = False,\n",
      "        is_text: bool = True,\n",
      "        errors: str | None = None,\n",
      "        storage_options: StorageOptions = None,\n",
      "    ) -> IOHandles[str] | IOHandles[bytes]:\n",
      "        \"\"\"\n",
      "        Get file handle for given path/buffer and mode.\n",
      "    \n",
      "        Parameters\n",
      "        ----------\n",
      "        path_or_buf : str or file handle\n",
      "            File path or object.\n",
      "        mode : str\n",
      "            Mode to open path_or_buf with.\n",
      "        encoding : str or None\n",
      "            Encoding to use.\n",
      "        {compression_options}\n",
      "    \n",
      "            .. versionchanged:: 1.0.0\n",
      "               May now be a dict with key 'method' as compression mode\n",
      "               and other keys as compression options if compression\n",
      "               mode is 'zip'.\n",
      "    \n",
      "            .. versionchanged:: 1.1.0\n",
      "               Passing compression options as keys in dict is now\n",
      "               supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\n",
      "    \n",
      "            .. versionchanged:: 1.4.0 Zstandard support.\n",
      "    \n",
      "        memory_map : bool, default False\n",
      "            See parsers._parser_params for more information.\n",
      "        is_text : bool, default True\n",
      "            Whether the type of the content passed to the file/buffer is string or\n",
      "            bytes. This is not the same as `\"b\" not in mode`. If a string content is\n",
      "            passed to a binary file/buffer, a wrapper is inserted.\n",
      "        errors : str, default 'strict'\n",
      "            Specifies how encoding and decoding errors are to be handled.\n",
      "            See the errors argument for :func:`open` for a full list\n",
      "            of options.\n",
      "        storage_options: StorageOptions = None\n",
      "            Passed to _get_filepath_or_buffer\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "    \n",
      "        Returns the dataclass IOHandles\n",
      "        \"\"\"\n",
      "        # Windows does not default to utf-8. Set to utf-8 for a consistent behavior\n",
      "        encoding = encoding or \"utf-8\"\n",
      "    \n",
      "        # read_csv does not know whether the buffer is opened in binary/text mode\n",
      "        if _is_binary_mode(path_or_buf, mode) and \"b\" not in mode:\n",
      "            mode += \"b\"\n",
      "    \n",
      "        # validate encoding and errors\n",
      "        codecs.lookup(encoding)\n",
      "        if isinstance(errors, str):\n",
      "            codecs.lookup_error(errors)\n",
      "    \n",
      "        # open URLs\n",
      "        ioargs = _get_filepath_or_buffer(\n",
      "            path_or_buf,\n",
      "            encoding=encoding,\n",
      "            compression=compression,\n",
      "            mode=mode,\n",
      "            storage_options=storage_options,\n",
      "        )\n",
      "    \n",
      "        handle = ioargs.filepath_or_buffer\n",
      "        handles: list[BaseBuffer]\n",
      "    \n",
      "        # memory mapping needs to be the first step\n",
      "        handle, memory_map, handles = _maybe_memory_map(\n",
      "            handle,\n",
      "            memory_map,\n",
      "            ioargs.encoding,\n",
      "            ioargs.mode,\n",
      "            errors,\n",
      "            ioargs.compression[\"method\"] not in _compression_to_extension,\n",
      "        )\n",
      "    \n",
      "        is_path = isinstance(handle, str)\n",
      "        compression_args = dict(ioargs.compression)\n",
      "        compression = compression_args.pop(\"method\")\n",
      "    \n",
      "        # Only for write methods\n",
      "        if \"r\" not in mode and is_path:\n",
      "            check_parent_directory(str(handle))\n",
      "    \n",
      "        if compression:\n",
      "            if compression != \"zstd\":\n",
      "                # compression libraries do not like an explicit text-mode\n",
      "                ioargs.mode = ioargs.mode.replace(\"t\", \"\")\n",
      "            elif compression == \"zstd\" and \"b\" not in ioargs.mode:\n",
      "                # python-zstandard defaults to text mode, but we always expect\n",
      "                # compression libraries to use binary mode.\n",
      "                ioargs.mode += \"b\"\n",
      "    \n",
      "            # GZ Compression\n",
      "            if compression == \"gzip\":\n",
      "                if is_path:\n",
      "                    assert isinstance(handle, str)\n",
      "                    # error: Incompatible types in assignment (expression has type\n",
      "                    # \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\n",
      "                    handle = gzip.GzipFile(  # type: ignore[assignment]\n",
      "                        filename=handle,\n",
      "                        mode=ioargs.mode,\n",
      "                        **compression_args,\n",
      "                    )\n",
      "                else:\n",
      "                    handle = gzip.GzipFile(\n",
      "                        # No overload variant of \"GzipFile\" matches argument types\n",
      "                        # \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\n",
      "                        fileobj=handle,  # type: ignore[call-overload]\n",
      "                        mode=ioargs.mode,\n",
      "                        **compression_args,\n",
      "                    )\n",
      "    \n",
      "            # BZ Compression\n",
      "            elif compression == \"bz2\":\n",
      "                # No overload variant of \"BZ2File\" matches argument types\n",
      "                # \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\n",
      "                handle = bz2.BZ2File(  # type: ignore[call-overload]\n",
      "                    handle,\n",
      "                    mode=ioargs.mode,\n",
      "                    **compression_args,\n",
      "                )\n",
      "    \n",
      "            # ZIP Compression\n",
      "            elif compression == \"zip\":\n",
      "                # error: Argument 1 to \"_BytesZipFile\" has incompatible type \"Union[str,\n",
      "                # BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\n",
      "                # ReadBuffer[bytes], WriteBuffer[bytes]]\"\n",
      "                handle = _BytesZipFile(\n",
      "                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]\n",
      "                )\n",
      "                if handle.mode == \"r\":\n",
      "                    handles.append(handle)\n",
      "                    zip_names = handle.namelist()\n",
      "                    if len(zip_names) == 1:\n",
      "                        handle = handle.open(zip_names.pop())\n",
      "                    elif len(zip_names) == 0:\n",
      "                        raise ValueError(f\"Zero files found in ZIP file {path_or_buf}\")\n",
      "                    else:\n",
      "                        raise ValueError(\n",
      "                            \"Multiple files found in ZIP file. \"\n",
      "                            f\"Only one file per ZIP: {zip_names}\"\n",
      "                        )\n",
      "    \n",
      "            # XZ Compression\n",
      "            elif compression == \"xz\":\n",
      "                handle = get_lzma_file()(handle, ioargs.mode)\n",
      "    \n",
      "            # Zstd Compression\n",
      "            elif compression == \"zstd\":\n",
      "                zstd = import_optional_dependency(\"zstandard\")\n",
      "                if \"r\" in ioargs.mode:\n",
      "                    open_args = {\"dctx\": zstd.ZstdDecompressor(**compression_args)}\n",
      "                else:\n",
      "                    open_args = {\"cctx\": zstd.ZstdCompressor(**compression_args)}\n",
      "                handle = zstd.open(\n",
      "                    handle,\n",
      "                    mode=ioargs.mode,\n",
      "                    **open_args,\n",
      "                )\n",
      "    \n",
      "            # Unrecognized Compression\n",
      "            else:\n",
      "                msg = f\"Unrecognized compression type: {compression}\"\n",
      "                raise ValueError(msg)\n",
      "    \n",
      "            assert not isinstance(handle, str)\n",
      "            handles.append(handle)\n",
      "    \n",
      "        elif isinstance(handle, str):\n",
      "            # Check whether the filename is to be opened in binary mode.\n",
      "            # Binary mode does not support 'encoding' and 'newline'.\n",
      "            if ioargs.encoding and \"b\" not in ioargs.mode:\n",
      "                # Encoding\n",
      ">               handle = open(\n",
      "                    handle,\n",
      "                    ioargs.mode,\n",
      "                    encoding=ioargs.encoding,\n",
      "                    errors=errors,\n",
      "                    newline=\"\",\n",
      "                )\n",
      "E               FileNotFoundError: [Errno 2] No such file or directory: 'df.сsv'\n",
      "\n",
      "..\\..\\..\\..\\..\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789: FileNotFoundError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________ ERROR at setup of test_R2 __________________________\n",
      "\n",
      "load_model = Pipeline(steps=[('columntransformer',\n",
      "                 ColumnTransformer(transformers=[('encoder',\n",
      "                   ...                               ['carat', 'x', 'y', 'z'])])),\n",
      "                ('linearregression', LinearRegression())])\n",
      "\n",
      "    @pytest.fixture()\n",
      "    def making_prediction(load_model):\n",
      ">       data = pd.read_csv(\"df.сsv\")\n",
      "\n",
      "test.py:16: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "..\\..\\..\\..\\..\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "..\\..\\..\\..\\..\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680: in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "..\\..\\..\\..\\..\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575: in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "..\\..\\..\\..\\..\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933: in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "..\\..\\..\\..\\..\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217: in _make_engine\n",
      "    self.handles = get_handle(  # type: ignore[call-overload]\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_or_buf = 'df.сsv', mode = 'r'\n",
      "\n",
      "    @doc(compression_options=_shared_docs[\"compression_options\"] % \"path_or_buf\")\n",
      "    def get_handle(\n",
      "        path_or_buf: FilePath | BaseBuffer,\n",
      "        mode: str,\n",
      "        *,\n",
      "        encoding: str | None = None,\n",
      "        compression: CompressionOptions = None,\n",
      "        memory_map: bool = False,\n",
      "        is_text: bool = True,\n",
      "        errors: str | None = None,\n",
      "        storage_options: StorageOptions = None,\n",
      "    ) -> IOHandles[str] | IOHandles[bytes]:\n",
      "        \"\"\"\n",
      "        Get file handle for given path/buffer and mode.\n",
      "    \n",
      "        Parameters\n",
      "        ----------\n",
      "        path_or_buf : str or file handle\n",
      "            File path or object.\n",
      "        mode : str\n",
      "            Mode to open path_or_buf with.\n",
      "        encoding : str or None\n",
      "            Encoding to use.\n",
      "        {compression_options}\n",
      "    \n",
      "            .. versionchanged:: 1.0.0\n",
      "               May now be a dict with key 'method' as compression mode\n",
      "               and other keys as compression options if compression\n",
      "               mode is 'zip'.\n",
      "    \n",
      "            .. versionchanged:: 1.1.0\n",
      "               Passing compression options as keys in dict is now\n",
      "               supported for compression modes 'gzip', 'bz2', 'zstd' and 'zip'.\n",
      "    \n",
      "            .. versionchanged:: 1.4.0 Zstandard support.\n",
      "    \n",
      "        memory_map : bool, default False\n",
      "            See parsers._parser_params for more information.\n",
      "        is_text : bool, default True\n",
      "            Whether the type of the content passed to the file/buffer is string or\n",
      "            bytes. This is not the same as `\"b\" not in mode`. If a string content is\n",
      "            passed to a binary file/buffer, a wrapper is inserted.\n",
      "        errors : str, default 'strict'\n",
      "            Specifies how encoding and decoding errors are to be handled.\n",
      "            See the errors argument for :func:`open` for a full list\n",
      "            of options.\n",
      "        storage_options: StorageOptions = None\n",
      "            Passed to _get_filepath_or_buffer\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "    \n",
      "        Returns the dataclass IOHandles\n",
      "        \"\"\"\n",
      "        # Windows does not default to utf-8. Set to utf-8 for a consistent behavior\n",
      "        encoding = encoding or \"utf-8\"\n",
      "    \n",
      "        # read_csv does not know whether the buffer is opened in binary/text mode\n",
      "        if _is_binary_mode(path_or_buf, mode) and \"b\" not in mode:\n",
      "            mode += \"b\"\n",
      "    \n",
      "        # validate encoding and errors\n",
      "        codecs.lookup(encoding)\n",
      "        if isinstance(errors, str):\n",
      "            codecs.lookup_error(errors)\n",
      "    \n",
      "        # open URLs\n",
      "        ioargs = _get_filepath_or_buffer(\n",
      "            path_or_buf,\n",
      "            encoding=encoding,\n",
      "            compression=compression,\n",
      "            mode=mode,\n",
      "            storage_options=storage_options,\n",
      "        )\n",
      "    \n",
      "        handle = ioargs.filepath_or_buffer\n",
      "        handles: list[BaseBuffer]\n",
      "    \n",
      "        # memory mapping needs to be the first step\n",
      "        handle, memory_map, handles = _maybe_memory_map(\n",
      "            handle,\n",
      "            memory_map,\n",
      "            ioargs.encoding,\n",
      "            ioargs.mode,\n",
      "            errors,\n",
      "            ioargs.compression[\"method\"] not in _compression_to_extension,\n",
      "        )\n",
      "    \n",
      "        is_path = isinstance(handle, str)\n",
      "        compression_args = dict(ioargs.compression)\n",
      "        compression = compression_args.pop(\"method\")\n",
      "    \n",
      "        # Only for write methods\n",
      "        if \"r\" not in mode and is_path:\n",
      "            check_parent_directory(str(handle))\n",
      "    \n",
      "        if compression:\n",
      "            if compression != \"zstd\":\n",
      "                # compression libraries do not like an explicit text-mode\n",
      "                ioargs.mode = ioargs.mode.replace(\"t\", \"\")\n",
      "            elif compression == \"zstd\" and \"b\" not in ioargs.mode:\n",
      "                # python-zstandard defaults to text mode, but we always expect\n",
      "                # compression libraries to use binary mode.\n",
      "                ioargs.mode += \"b\"\n",
      "    \n",
      "            # GZ Compression\n",
      "            if compression == \"gzip\":\n",
      "                if is_path:\n",
      "                    assert isinstance(handle, str)\n",
      "                    # error: Incompatible types in assignment (expression has type\n",
      "                    # \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\n",
      "                    handle = gzip.GzipFile(  # type: ignore[assignment]\n",
      "                        filename=handle,\n",
      "                        mode=ioargs.mode,\n",
      "                        **compression_args,\n",
      "                    )\n",
      "                else:\n",
      "                    handle = gzip.GzipFile(\n",
      "                        # No overload variant of \"GzipFile\" matches argument types\n",
      "                        # \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\n",
      "                        fileobj=handle,  # type: ignore[call-overload]\n",
      "                        mode=ioargs.mode,\n",
      "                        **compression_args,\n",
      "                    )\n",
      "    \n",
      "            # BZ Compression\n",
      "            elif compression == \"bz2\":\n",
      "                # No overload variant of \"BZ2File\" matches argument types\n",
      "                # \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\n",
      "                handle = bz2.BZ2File(  # type: ignore[call-overload]\n",
      "                    handle,\n",
      "                    mode=ioargs.mode,\n",
      "                    **compression_args,\n",
      "                )\n",
      "    \n",
      "            # ZIP Compression\n",
      "            elif compression == \"zip\":\n",
      "                # error: Argument 1 to \"_BytesZipFile\" has incompatible type \"Union[str,\n",
      "                # BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\n",
      "                # ReadBuffer[bytes], WriteBuffer[bytes]]\"\n",
      "                handle = _BytesZipFile(\n",
      "                    handle, ioargs.mode, **compression_args  # type: ignore[arg-type]\n",
      "                )\n",
      "                if handle.mode == \"r\":\n",
      "                    handles.append(handle)\n",
      "                    zip_names = handle.namelist()\n",
      "                    if len(zip_names) == 1:\n",
      "                        handle = handle.open(zip_names.pop())\n",
      "                    elif len(zip_names) == 0:\n",
      "                        raise ValueError(f\"Zero files found in ZIP file {path_or_buf}\")\n",
      "                    else:\n",
      "                        raise ValueError(\n",
      "                            \"Multiple files found in ZIP file. \"\n",
      "                            f\"Only one file per ZIP: {zip_names}\"\n",
      "                        )\n",
      "    \n",
      "            # XZ Compression\n",
      "            elif compression == \"xz\":\n",
      "                handle = get_lzma_file()(handle, ioargs.mode)\n",
      "    \n",
      "            # Zstd Compression\n",
      "            elif compression == \"zstd\":\n",
      "                zstd = import_optional_dependency(\"zstandard\")\n",
      "                if \"r\" in ioargs.mode:\n",
      "                    open_args = {\"dctx\": zstd.ZstdDecompressor(**compression_args)}\n",
      "                else:\n",
      "                    open_args = {\"cctx\": zstd.ZstdCompressor(**compression_args)}\n",
      "                handle = zstd.open(\n",
      "                    handle,\n",
      "                    mode=ioargs.mode,\n",
      "                    **open_args,\n",
      "                )\n",
      "    \n",
      "            # Unrecognized Compression\n",
      "            else:\n",
      "                msg = f\"Unrecognized compression type: {compression}\"\n",
      "                raise ValueError(msg)\n",
      "    \n",
      "            assert not isinstance(handle, str)\n",
      "            handles.append(handle)\n",
      "    \n",
      "        elif isinstance(handle, str):\n",
      "            # Check whether the filename is to be opened in binary mode.\n",
      "            # Binary mode does not support 'encoding' and 'newline'.\n",
      "            if ioargs.encoding and \"b\" not in ioargs.mode:\n",
      "                # Encoding\n",
      ">               handle = open(\n",
      "                    handle,\n",
      "                    ioargs.mode,\n",
      "                    encoding=ioargs.encoding,\n",
      "                    errors=errors,\n",
      "                    newline=\"\",\n",
      "                )\n",
      "E               FileNotFoundError: [Errno 2] No such file or directory: 'df.сsv'\n",
      "\n",
      "..\\..\\..\\..\\..\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789: FileNotFoundError\n",
      "=========================== short test summary info ===========================\n",
      "ERROR test.py::test_MAE - FileNotFoundError: [Errno 2] No such file or direct...\n",
      "ERROR test.py::test_R2 - FileNotFoundError: [Errno 2] No such file or directo...\n",
      "============================== 2 errors in 3.61s ==============================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pytest -v test.py\n",
    "#%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e877e6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\v.zemov\\\\Desktop\\\\Master\\\\2 семестр ИИ\\\\Автоматизация машин_обучения\\\\lab_5\\\\df_1'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
